{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "versioninfo()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Julia Version 1.6.2\n",
      "Commit 1b93d53fc4 (2021-07-14 15:36 UTC)\n",
      "Platform Info:\n",
      "  OS: Windows (x86_64-w64-mingw32)\n",
      "  CPU: Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-11.0.1 (ORCJIT, skylake)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "using Pkg\r\n",
    "Pkg.activate(\"../..\")\r\n",
    "Pkg.status()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m "
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[32m\u001b[1m      Status\u001b[22m\u001b[39m"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "new environment at `c:\\Project.toml`\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " `C:\\Project.toml` (empty project)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Algorithms\r\n",
    "\r\n",
    "* Algorithm is loosely defined as a set of instructions for doing something, which terminates in finite time. An algorithm requires input and output.\r\n",
    "\r\n",
    "* [Donald Knuth](https://en.wikipedia.org/wiki/The_Art_of_Computer_Programming): (1) finiteness, (2) definiteness, (3) input, (4) output, (5) effectiveness. [Five things that Algorithm should have]\r\n",
    "\r\n",
    "\r\n",
    "## Measure of efficiency\r\n",
    "\r\n",
    "* A basic unit for measuring algorithmic efficiency is **flop**.  \r\n",
    "> A flop (**floating point operation**) consists of a floating point addition, subtraction, multiplication, division, or comparison, and the usually accompanying fetch and store.  \r\n",
    "\r\n",
    "Some books count multiplication followed by an addition (fused multiply-add, FMA) as one flop. This results a factor of up to 2 difference in flop counts.\r\n",
    "\r\n",
    "* How to measure efficiency of an algorithm? Big O notation. If $n$ is the size of a problem, an algorithm has order $O(f(n))$, where the leading term in the number of flops is $c \\cdot f(n)$. For example,\r\n",
    "    - matrix-vector multiplication `A * b`, where `A` is $m \\times n$ and `b` is $n \\times 1$, takes $2mn$ or $O(mn)$ flops\r\n",
    "        - $m$ dot products of $n$-dimensional vectors. dot product of $n$-dimensional vectors require $n$ multiplications and $n$ (or exactly $n-1$) additions.  \r\n",
    "    - matrix-matrix multiplication `A * B`, where `A` is $m \\times n$ and `B` is $n \\times p$, takes $2mnp$ or $O(mnp)$ flops\r\n",
    "    - If `A`, `B` are $n\\times n$ dimensional matrices and `b` is $n$-dimensional vector then `A * b` takes $O(n^2)$ flops and `A * B` takes $O(n^3)$ flops.\r\n",
    "\r\n",
    "* A hierarchy of computational complexity:  \r\n",
    "    Let $n$ be the problem size.\r\n",
    "    - Exponential order: $O(b^n)$ (\"horrible\" ; as $n$ grows by 1, required flops increases to b times its value.)    \r\n",
    "    - Polynomial order: $O(n^q)$ (doable)  \r\n",
    "    - $O(n \\log n )$ (fast)  \r\n",
    "    - Linear order $O(n)$ (fast)  \r\n",
    "    - Logarithmic order $O(\\log n)$ (super fast)  \r\n",
    "    \r\n",
    "* Classification of data sets by [Huber](http://link.springer.com/chapter/10.1007%2F978-3-642-52463-9_1) (1994).\r\n",
    "\r\n",
    "| Data Size | Bytes     | Storage Mode          |\r\n",
    "|-----------|-----------|-----------------------|\r\n",
    "| Tiny      | $10^2$    | Piece of paper        |\r\n",
    "| Small     | $10^4$    | A few pieces of paper |\r\n",
    "| Medium    | $10^6$ (megabytes)    | A floppy disk         |\r\n",
    "| Large     | $10^8$    | Hard disk             |\r\n",
    "| Huge      | $10^9$ (gigabytes)   | Hard disk(s)          |\r\n",
    "| Massive   | $10^{12}$ (terabytes) | RAID storage          |\r\n",
    "\r\n",
    "In today's bigdata age, notion for data size shifts to right about $10^3$.\r\n",
    "\r\n",
    "* Difference of $O(n^2)$ and $O(n\\log n)$ on massive data. Suppose we have a teraflops supercomputer capable of doing $10^{12}$ flops per second. For a problem of size $n=10^{12}$, $O(n \\log n)$ algorithm takes about \r\n",
    "$$10^{12} \\log (10^{12}) / 10^{12} \\approx 27 \\text{ seconds}.$$ \r\n",
    "$O(n^2)$ algorithm takes about $10^{24}/10^{12} = 10^{12}$ seconds, which is approximately 31710 years! (Problem is, $n=10^{12}$ is not unrealistically large problem size in these days. In fact, it is quite common problem size nowadays.)\r\n",
    "\r\n",
    "* QuickSort and Fast Fourier Transform (invented by John Tukey) are celebrated algorithms that turn $O(n^2)$ operations into $O(n \\log n)$. Another example is the Strassen's method for matrix multiplication, which turns $O(n^3)$ matrix multiplication into $O(n^{\\log_2 7})$.\r\n",
    "    - Past algorithms for sorting and FFT typically had order $O(n^2)$. QuickSort algorithm is known to be optimal one. Tukey invented algorithm for FFT having order $O(n\\log n)$.\r\n",
    "    - Naive implementation for matrix multiplication has order $O(n^3)$. Strassen's method attains order $O(n^{\\log_2 7})$ where $2<\\log_2 7<3$.    \r\n",
    "\r\n",
    "* One goal of this course is to get familiar with the flop counts for some common numerical tasks in statistics.   \r\n",
    "> **The form of a mathematical expression and the way the expression should be evaluated in actual practice may be quite different.**\r\n",
    "\\\r\n",
    "    -- James Gentle, *Matrix Algebra*, Springer, New York (2007).\r\n",
    "\r\n",
    "\r\n",
    "* For example, compare flops of the two mathematically equivalent expressions: `A * B * x` and `A * (B * x)` where `A` and `B` are matrices and `x` is a vector.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "using BenchmarkTools, Random\r\n",
    "\r\n",
    "Random.seed!(123) # seed\r\n",
    "n = 1000\r\n",
    "A = randn(n, n)\r\n",
    "B = randn(n, n)\r\n",
    "x = randn(n)\r\n",
    "\r\n",
    "# complexity is n^3 + n^2 = O(n^3)\r\n",
    "@benchmark $A * $B * $x"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 269 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m14.510 ms\u001b[22m\u001b[39m … \u001b[35m97.294 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 80.63%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m18.157 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m18.627 ms\u001b[22m\u001b[39m ± \u001b[32m 6.956 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m3.13% ±  6.96%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▃\u001b[39m▃\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▃\u001b[34m▃\u001b[39m\u001b[39m▅\u001b[39m█\u001b[39m▁\u001b[32m▂\u001b[39m\u001b[39m▁\u001b[39m \u001b[39m▃\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▃\u001b[39m▇\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m▅\u001b[39m▆\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[39m▄\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▅\u001b[39m▇\u001b[39m▇\u001b[39m▄\u001b[39m█\u001b[39m▄\u001b[39m▅\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▄\u001b[39m▃\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▃\u001b[39m \u001b[39m▄\n",
       "  14.5 ms\u001b[90m         Histogram: frequency by time\u001b[39m        22.4 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m7.64 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m3\u001b[39m."
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# complexity is n^2 + n^2 = O(n^2)\r\n",
    "@benchmark $A * ($B * $x)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 7629 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m496.037 μs\u001b[22m\u001b[39m … \u001b[35m  3.428 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m542.873 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m639.769 μs\u001b[22m\u001b[39m ± \u001b[32m224.916 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m▆\u001b[34m▅\u001b[39m\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[32m▃\u001b[39m\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▆\u001b[39m▄\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m \u001b[39m█\n",
       "  496 μs\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m       1.63 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m15.88 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m2\u001b[39m."
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since 1000 $\\mu s$ (microseconds) = 1 $ms$ (millisecond), elapsed time for `A * B * x` is about 30 times bigger than `A * (B * x)` given problem size $n=1000$.  \r\n",
    "Notice that memory allocation, other than flop counts, is also a criteria for computational complexity of algorithm. `A * B * x` requires about 500 times larger memory allocation than `A * (B * x)`.  \r\n",
    "In short, `A * (B * x)` uses less resource (time and memory) than `A * B * x`  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Why are there the difference?\r\n",
    "- $(AB)x=A(Bx)$ by associative law. For computation, $(AB)x$ involves one matrix-matrix multiplication and one matrix-vector multiplication while $A(Bx)$ involves two matrix-vector multiplications.\r\n",
    "- Flop count : $O(n^3)$ vs $O(n^2)\\quad / \\quad $  Memory allocation : $O(n^2)$ vs $O(n)$\r\n",
    "- Mathematical expression $ABx$ may suggest `A * B * x`, but in actual practice, `A * (B * x)` is a better choice for the evaluation in numerical sense."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Performance of computer systems\n",
    "\n",
    "* **FLOPS**. \n",
    "\n",
    "* For example, my laptop has the Intel i5-8279U (Coffee Lake) CPU with 4 cores runing at 2.4 GHz (cycles per second)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "versioninfo()\r\n",
    "# core : the number of CPU. 4cores computer can simultaneously compute four operations.\r\n",
    "# clock speed : computer computes one operation per each cycle of clock. 3.2GHZ means clock bounces 3.2 * 10^9 cycles per second.\r\n",
    "# word-size : 64bit computer can deal with 64 bit object at once during computation.\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Julia Version 1.6.2\n",
      "Commit 1b93d53fc4 (2021-07-14 15:36 UTC)\n",
      "Platform Info:\n",
      "  OS: Windows (x86_64-w64-mingw32)\n",
      "  CPU: Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-11.0.1 (ORCJIT, skylake)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Intel Coffee Lake CPUs can do 16 double-precision flops per cycle and 32 single-precision flops per cycle. Then the **theoretical throughput** of my laptop is\r\n",
    "$$ 4 \\times 2.4 \\times 10^9 \\times 16 = 153.6  \\text{ GFLOPS} $$\r\n",
    "in double precision and\r\n",
    "$$ 4 \\times 2.4 \\times 10^9 \\times 32 = 307.2  \\text{ GFLOPS} $$\r\n",
    "in single precision.  \r\n",
    "* Terraflops is equal to 1000 GFLOPS(gigaflops). Thus my desktop has $1/6$ speed of terraflops supercomputer.\r\n",
    "\r\n",
    "* In Julia, `LinearAlgebra.peakflops()` computes the peak flop rate of the computer by using `gemm!` (double precision  matrix-matrix multiplication, which is well optimized routine)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "using LinearAlgebra\r\n",
    "\r\n",
    "LinearAlgebra.peakflops(2^14) # matrix size 2^14\r\n",
    "\r\n",
    "# CPU를 학대함으로써 퍼포먼스 최대치(peakflop)를 끌어내보자는 것"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6.686463987238992e10"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "which is about 147.4 GFLOPS DP."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stability of numerical algorithms\r\n",
    "\r\n",
    "* Recall that abstractly, a *problem* can be viewed as function $f: \\mathcal{X} \\to \\mathcal{Y}$ where $\\mathcal{X}$ is a normed vector space of data and $\\mathcal{Y}$ is a normed vector space of solutions.\r\n",
    "\\\r\n",
    "For given data $x \\in \\mathcal{X}$, the true solution of the problem $f$ is $y = f(x) \\in \\mathcal{Y}$. \r\n",
    "    - The problem of solving $Ax=b$ for fixed $b$ is $f$ defined by $ A \\mapsto A^{-1}b$ with $\\mathcal{X}=\\{M\\in\\mathbb{R}^{n\\times n}: M \\text{ is invertible} \\}$ and $\\mathcal{Y} = \\mathbb{R}^n$.\r\n",
    "\r\n",
    "    \r\n",
    "* An *algorithm* can be viewed as another map $\\tilde{f}: \\mathcal{X} \\to \\mathcal{Y}$ (algorithm approximates $f$ by $\\tilde{f}$ )\r\n",
    "    * This is because of some constraint : finite precision of computer, efficiency and design of algorithm, etc.\r\n",
    "    * Stability can be a criteria for good algorithm in aspect of accuracy other than complexity  \r\n",
    "\\\r\n",
    "For given data $x \\in \\mathcal{X}$, the solution **computed** by algorithm $\\tilde{f}$ is $\\hat{y} = \\tilde{f}(x) \\in \\mathcal{Y}$. \r\n",
    "    - Example 1: solve $Ax=b$ by GEPP followed by forward and backward substitutions on a digital computer. ($\\hat y_1= \\tilde{f}_1(x)$)\r\n",
    "    - Example 2: solve $Ax=b$ by Gauss-Seidel (an iterative method to come) on a digital computer.  ($\\hat y_2= \\tilde{f}_2(x)$)\r\n",
    "    - In both cases, the solutions (in $\\mathcal{Y}$) are not the same as $A^{-1}b$! ($y$ need not be same with $\\hat y_1$ or $\\hat y_2$)\r\n",
    "        + We'll learn about these algorithms soon.\r\n",
    "    - Algorithms will be affected by at least rounding errors.\r\n",
    "    \r\n",
    "* It is not necessarily true that $\\hat{y} = y$, or $\\tilde{f}(x) = f(x)$. The forward error of a computed solution is the relative error\r\n",
    "$$\r\n",
    "    \\frac{\\Vert \\tilde{f}(x) - f(x) \\Vert}{\\Vert f(x) \\Vert}\r\n",
    "    .\r\n",
    "$$\r\n",
    "We want that the forward error should be bounded.\r\n",
    "    \r\n",
    "* Algorithm $\\tilde{f}$ is said *stable* if\r\n",
    "$$\r\n",
    "    \\forall x \\in \\mathcal{X}, \r\n",
    "    \\exists \\tilde{x} \\in \\mathcal{X} \\text{ such that }\r\n",
    "    \\frac{\\|\\tilde{x} - x\\|}{\\|x\\|} = O(\\epsilon)\r\n",
    "    \\implies\r\n",
    "    \\frac{\\|\\tilde{f}(x) - f(\\tilde{x})\\|}{\\|f(\\tilde{x})\\|} = O(\\epsilon)\r\n",
    "    ,\r\n",
    "    \\quad\r\n",
    "    \\text{as}~ \\epsilon \\to 0\r\n",
    "    .\r\n",
    "$$\r\n",
    "In words, a stable algorithm gives \"nearly the right\" answer to a \"slightly wrong\" question.  \r\n",
    "$\\tilde{x}$ : a slightly wrong question. $\\quad f(\\tilde{x})$ : the right answer to a sligtly wrong question. $\\quad \\tilde{f}(x)$ : what an algorithm gives  \r\n",
    "Note that the definition of *stable algorithm* is differed from the concept of stability which is related to bounded forward error.\r\n",
    "\r\n",
    "* Backward stability: algorithm $\\tilde{f}$ is said *backward stable* if\r\n",
    "$$\r\n",
    "    \\forall x \\in \\mathcal{X}, \r\n",
    "    \\exists \\tilde{x} \\in \\mathcal{X} \\text{ such that }\r\n",
    "    \\frac{\\|\\tilde{x} - x\\|}{\\|x\\|} = O(\\epsilon)\r\n",
    "    \\implies\r\n",
    "    \\tilde{f}(x) = f(\\tilde{x})\r\n",
    "    ,\r\n",
    "    \\quad\r\n",
    "    \\text{as}~ \\epsilon \\to 0\r\n",
    "$$\r\n",
    "In words, a backward stable algorithm gives \"exactly the right\" answer to a \"slightly wrong\" question.\r\n",
    "    - Backward stability implies stability, but not the other way around.\r\n",
    "\r\n",
    "* If a backward stable algorithm $\\tilde{f}$ is applied to solve a problem $f$, the forward error of $\\tilde{f}$ is bounded by the condition number of problem $f$. \r\n",
    "\\\r\n",
    "\\\r\n",
    "To see this, recall the definition of the condition number \r\n",
    "$$\r\n",
    "    \\kappa = \\lim_{\\delta\\to 0}\\sup_{\\|\\tilde{x} - x\\|\\le \\delta \\Vert x \\Vert}\\frac{\\|f(\\tilde{x}) - f(x)\\|/\\|f(x)\\|}{\\|\\tilde{x} - x\\|/\\|x\\|}\r\n",
    "    .\r\n",
    "$$\r\n",
    "Thus for $\\tilde{x} \\in \\mathcal{X}$ such that $\\frac{\\Vert\\tilde{x} - x\\Vert}{\\Vert x \\Vert} = O(\\epsilon)$ and $\\tilde{f}(x) = f(\\tilde{x})$  as $\\epsilon \\to 0$, we have\r\n",
    "$$\r\n",
    "    \\frac{\\|\\tilde{f}(x) - f(x)\\|}{\\|f(x)\\|} \\le ( \\kappa + o(1) )\\frac{\\|\\tilde{x} - x\\|}{\\|x\\|}\r\n",
    "    = O(\\kappa \\epsilon)\r\n",
    "    .\r\n",
    "$$\r\n",
    "$$\r\n",
    "\\begin{align*}\r\n",
    "    \\because \\frac{\\|\\tilde{f}(x) - f(x)\\|}{\\|f(x)\\|} &=\\frac{\\|f(\\tilde{x}) - f(x)\\|}{\\|f(x)\\|} \\\\ &\\leq \\frac{\\|\\tilde{x}-x\\|}{\\|x\\|}\\sup_{\\|\\hat{x} - x\\|\\le \\delta \\Vert x \\Vert}\\frac{\\|f(\\hat{x}) - f(x)\\|/\\|f(x)\\|}{\\|\\hat{x} - x\\|/\\|x\\|} \\\\\r\n",
    "    As\\; \\delta\\rightarrow 0, \\; \\frac{\\|\\tilde{f}(x) - f(x)\\|}{\\|f(x)\\|} &\\leq \\frac{\\|\\tilde{x}-x\\|}{\\|x\\|} \\kappa = O(\\epsilon)\\kappa=O(\\kappa \\epsilon)  \r\n",
    "\\end{align*}\r\n",
    "$$\r\n",
    "\r\n",
    "\r\n",
    "* Examples\r\n",
    "    - Computing the inner product $x^Ty$ of vectors $x$ and $y$ using by $[\\sum_{i=1}^n [[x_i][y_i]]]$ (in IEEE754) is backward stable.\r\n",
    "    - Computing the outer product $A=xy^T$ of vectors $x$ and $y$ using by $A_{ij}=[[x_i][y_j]]$ (in IEEE754) is  stable but *not* backward stable.\r\n",
    "    \r\n",
    "* **(Backward) Stability is a property of an algorithm, whereas conditioning is a property of a problem (and an input data).**\r\n",
    "    - Consider solving $Ax=b$ for fixed $b$. Then *conditioning* focuses on \"how singular input $A$ is\", while *stability* deals with that given $A$ and $b$, \"how stable the solution derived by an algorithm is\"   "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading\n",
    "\n",
    "[What is Numerical Stability?](https://nhigham.com/2020/08/04/what-is-numerical-stability/) by Nick Higham\n",
    "\n",
    "## Acknowledgment\n",
    "\n",
    "This lecture note has evolved from [Dr. Hua Zhou](http://hua-zhou.github.io)'s 2019 Spring Statistical Computing course notes available at <http://hua-zhou.github.io/teaching/biostatm280-2019spring/index.html>."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "67px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}